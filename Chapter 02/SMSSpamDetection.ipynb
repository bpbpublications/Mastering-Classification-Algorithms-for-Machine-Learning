{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec5f910-110a-4453-912b-3858b077cf95",
   "metadata": {},
   "source": [
    "# Detecting Spam SMS using Naive Bayes Algorithm\n",
    "\n",
    "**Author:** Partha Majumdar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7ecd2-b9aa-4d4e-bc34-07eb51a7c131",
   "metadata": {},
   "source": [
    "In this notebook, we will explore Python code for implementing **Naive Bayes algorithm** to detect **spam SMS**. SMS is a service provided by Mobile service providers using which Mobile users can send messages to other Mobile users. SMS stands for **Short Messaging Service**. Using SMS, Mobile users can send message which can at the most contain 160 characters. The messages can contain any character and can include hyperlinks.\n",
    "\n",
    "The model being built is a **Supervised Learning** model. In other words, we will feed data containing spam SMS and good SMS along with labels regarding which SMS is a spam SMS and which SMS is a good SMS into the machine and make the machine learn to detect spam SMS and good SMS. Once the model is ready, if we feed any SMS to the model, the model should respond by stating whether the input SMS is a spam SMS or a good SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3c12049-a1ae-425a-b7d2-d44d03e9c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e6b55-bdf2-4b57-bd90-24038b9928eb",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "The first step in building a supervised learning model is to load the data based on which the model will be prepared. The data for building this model is available in the file **[spamSMSDataset.csv](https://drive.google.com/file/d/1BA_TG8czxacEj0tq-q4QzhlPgYqAYhBp/view?usp=sharing)**. We will use the **pandas** **read_csv()** function to read the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028e1640-e7f9-4684-8dd3-e8ab547eb403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b1ebfa-dca4-480c-8f77-8974617fba1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2 Unnamed: 2  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1      ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3      ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "...    ...                                                ...        ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...        NaN   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?        NaN   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...        NaN   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...        NaN   \n",
       "5571   ham                         Rofl. Its true to its name        NaN   \n",
       "\n",
       "     Unnamed: 3 Unnamed: 4  \n",
       "0           NaN        NaN  \n",
       "1           NaN        NaN  \n",
       "2           NaN        NaN  \n",
       "3           NaN        NaN  \n",
       "4           NaN        NaN  \n",
       "...         ...        ...  \n",
       "5567        NaN        NaN  \n",
       "5568        NaN        NaN  \n",
       "5569        NaN        NaN  \n",
       "5570        NaN        NaN  \n",
       "5571        NaN        NaN  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a dataframe and display the dataframe\n",
    "df = pd.read_csv('spamSMSDataset.csv', encoding = 'latin-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5b8b34-b7b4-44eb-8449-26f6d6055cbb",
   "metadata": {},
   "source": [
    "If the dataframe is uploaded correctly, you will notice that the dataframe has 5 columns and 5572 rows. The columns should be named v1, v2, Unnamed: 2, Unnamed: 3, and Unnamed: 4. The column v2 contains the SMS text and the column v1 contains the label when the associated SMS text in column v2 is a Spam SMS or a Good SMS. We only need columns v1 and v2. So, we will first retain only the columns v1 and v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b3c3296-6342-4ce1-b802-846a43b64ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['v1', 'v2']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63a5d1-0adf-415b-a2e4-ede8dc030ffb",
   "metadata": {},
   "source": [
    "Here, column v2 is our independent variable and column v1 is the dependent variable.\n",
    "\n",
    "Let us see the unique values in this column v1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7ed21e-b69d-494c-85bd-a54928dbcf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the unique values in the column v1 in the dataframe df\n",
    "df.v1.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a359476f-83a6-4316-b3c1-96a4b6898682",
   "metadata": {},
   "source": [
    "Notice that column v1 has 2 values - ham and spam. Here, **ham** indicates that the corresponding SMS is a good SMS and **spam** indicates that the corresponding SMS is a spam SMS.\n",
    "\n",
    "Let us check how many SMS of the 2 types we have in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a030067-2da0-4cfe-84ac-35fb06310bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.v1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cd6b9f-8248-4c42-8aef-8414d3924bd5",
   "metadata": {},
   "source": [
    "We see that the dataset is not balanced as the number of good SMS examples is nearly 7 times that of the number of spam SMS.\n",
    "\n",
    "Now, column v1 (which is our dependent variable) contains the text 'ham' or 'spam'. However, we know that the computer cannot make anything out of the text available in column **v1**. So, we have to convert the contents of column **v1** to numbers. We will use **Label Encoder** to encode the values in column v1 to numbers. Label Encoders pick up the unique values in a column and assign a value starting with 0 till (n - 1), where n is the number of unique values in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c325fe9b-dbf8-409d-9a42-7d1ac166fecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2  label\n",
      "0   ham  Go until jurong point, crazy.. Available only ...      0\n",
      "1   ham                      Ok lar... Joking wif u oni...      0\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
      "3   ham  U dun say so early hor... U c already then say...      0\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...      0\n",
      "\n",
      "Unique values of the column \"label\" [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['v1'])\n",
    "print(df.head())\n",
    "print('\\nUnique values of the column \"label\"', df.label.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454fe07-6a2e-4d56-ae9b-3c02b3b20559",
   "metadata": {},
   "source": [
    "Let us take the contents of column v2 to a variable X. X will be our independent variable.\n",
    "\n",
    "And let us take the contents of the column label to a variable Y. Y will be our dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519a7fad-92c9-4ac0-aa82-0fd39b933da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['v2']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e908a3e-4d37-47bf-b36a-f2f4d0984003",
   "metadata": {},
   "source": [
    "Let us check how many examples of good emails we have and how many examples of spam emails we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b80616-cc93-479a-9536-97dd891301c8",
   "metadata": {},
   "source": [
    "## Creating and Training and Test sets\n",
    "\n",
    "\n",
    "We will split the data at random so that we have 2 sets. We will use one set for training our model and the other set to validate the goodness of the model. We will split the data such that 90% of the data is used for training and the rest 10% will be used for validation.\n",
    "\n",
    "To split the data into training and test sets, we will use the function **train_test_split()** from the **Scikit-Learn** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f14fca8-fa5f-4749-80ab-5460b7a16d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in the training set = 5014\n",
      "Number of data points in the test set = 558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)\n",
    "print(\"Number of data points in the training set = %d\" % (X_train.shape[0]))\n",
    "print(\"Number of data points in the test set = %d\" % (X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083f31f-aa9c-4873-a40a-fb25678db212",
   "metadata": {},
   "source": [
    "train_test_split() returns 4 datasets. We have captured these datasets in the variables X_train, X_test, y_train, and y_test. X_train contains 90% (in our case) of the rows from the original dataset (i.e. X) chosen at random and only contains the columns related to the independent variables. y_train contains the corresponding values of the dependent variable in relation to the dataset X_train. X_test contains the rest of the 10% of the rows from the original dataset (i.e. X) and contains only the columns corresponding to the independent variables. y_test contains the corresponding values of the dependent variable in relation to the dataset X_test.\n",
    "\n",
    "We will train the model using X_train and y_train.\n",
    "\n",
    "We will test the model by making predictions using X_test.\n",
    "\n",
    "We will measure the goodness of the model by comparing the predictions made on X_test to the actual values in y_test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abfda3-8f9d-4f90-876d-58e34722f939",
   "metadata": {},
   "source": [
    "## Pre-processing the data\n",
    "\n",
    "As stated before, we need to find a way to represent the text data as numbers. One way to do this is by preparing **TF-IDF (Term Frequency - Inverse Document Frequency)** for every data point. We refer to such a data as a vector of TF-IDFs. However, before we create the vector of TF-IDFs, we can remove non-essential words/elements from our data.\n",
    "\n",
    "Among the non-essential words/elements are the following:\n",
    "1. Commonly used words like a, an, the, etc. These are referred to as **Stop Words**.\n",
    "2. Punctuations and Special Characters\n",
    "3. URLs\n",
    "4. Numbers\n",
    "5. Extra white spaces\n",
    "\n",
    "Among the above categories, URL is a special category. Generally, spam SMS contain some URLs. As we cannot let the computer infer from the URL, we will make a column in our X dataframe to contain a value of 1 if an URL is present in X and 0 if there is no URL in the X. Let us do this first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23159ab-3cfc-43f8-973e-3bff29babca5",
   "metadata": {},
   "source": [
    "### Function to detect whether one or more URLs are present in the text\n",
    "\n",
    "Let us write a function to detect whether one or more URL is present in a provided text. The function returns a 1 is one or more URL are present in the text and remove the URL from the text. The function should return a 0 if the text contains no URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425aa112-f4f7-4626-8640-2457bf0910fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def identifyAndRemoveURLs(text):\n",
    "    present = re.search(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', text)\n",
    "    if present:\n",
    "        return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text), 1\n",
    "    else:\n",
    "        return text, 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c4b81-8031-44fa-adbb-fc11e1714ca2",
   "metadata": {},
   "source": [
    "Let us test this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bafbbc-81bb-4c2e-afbb-2c939b649bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: ('Click this link to register -  OR this link for information -  or download this file - ', 1)\n",
      "Example 2: ('This contains no URLs', 0)\n"
     ]
    }
   ],
   "source": [
    "print('Example 1:', identifyAndRemoveURLs(\"Click this link to register - https://www.fake.com OR this link for information - http://info.org or download this file - file://test.txt\"))\n",
    "print('Example 2:', identifyAndRemoveURLs('This contains no URLs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244d1aac-53f9-4bff-8869-4c6eb0c05b56",
   "metadata": {},
   "source": [
    "Let us now apply this function to the training dataset and remove all the URLs from the text. Also, let us make a new Series called URLPresent which will contain a 1 or 0 to indicate whether the corresponding text in X_train contained a URL or not respectively.\n",
    "\n",
    "Once we have converted X_train to TF-IDF, we will add URLPresent to the TF-iDF to form the data to be used for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9de3e4-e5ff-4f6e-80e6-cbd85db9db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Text:\n",
      " 0    LookAtMe!: Thanks for your purchase of a video...\n",
      "1          Aight, I'll hit you up when I get some cash\n",
      "2                           Don no da:)whats you plan?\n",
      "3                        Going to take your babe out ?\n",
      "4    No need lar. Jus testing e phone card. Dunno n...\n",
      "dtype: object\n",
      "\n",
      "URL Present Indicator:\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "URLPresent = pd.Series([identifyAndRemoveURLs(text)[1] for text in X_train])\n",
    "X_train = pd.Series([identifyAndRemoveURLs(text)[0] for text in X_train])\n",
    "\n",
    "print('New Text:\\n', X_train.head())\n",
    "print('\\nURL Present Indicator:\\n', URLPresent.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c5078-8e81-4be6-b845-5b58ebd25bf1",
   "metadata": {},
   "source": [
    "### Functions to remove non-essential elements from the data\n",
    "\n",
    "We will now write functions to remove the non-essential elements from the data. We will then collect all these individual functions into a single function so that they could be applied as a whole on the complete dataset.\n",
    "\n",
    "#### Function to remove Stop Words\n",
    "\n",
    "We can get a list of Stop Words in English from the **Natural Language Tool Kit (nltk)** library. We will get this list and from every data point we will remove these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cfa9c90-46c1-46a0-87df-a219021f9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries \n",
    "import nltk\n",
    "from   nltk.corpus import stopwords\n",
    "from   nltk.tokenize import word_tokenize\n",
    "\n",
    "# Gather the list of Stop Words\n",
    "stopWordList = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Function to remove Stop Words\n",
    "def removeStopWords(text):\n",
    "    # splitting strings into tokens (list of words)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    # filtering out the stop words\n",
    "    filtered_tokens = [token for token in tokens if token not in stopWordList]\n",
    "    filtered_text = ' '.join(filtered_tokens) \n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c4d1c-e3a4-4dda-87d8-972b107471ae",
   "metadata": {},
   "source": [
    "We now test our function.\n",
    "\n",
    "We will pass all the data in our test string in lowercase.\n",
    "\n",
    "This is because we will convert all the data in our text column to lowercase before building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8933f0-bfdd-4336-9fc6-29b87c9461da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test stop word remover'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeStopWords(\"This is a test of Stop Word remover\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aaa09f-a988-4b73-8376-6e229b1412f2",
   "metadata": {},
   "source": [
    "However, we will not be supplying one row at a time to this function. We will want all the rows in our dataframe to be treated by this function. To do this, we will use the code below.\n",
    "\n",
    "*As we are just testing the function, we will make a copy of the dataset and try the function on that copy. This way, we will not disturb our original dataset which we will treat later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffdf9bb7-6cd2-4a9e-90ff-013167f16bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "0    LookAtMe!: Thanks for your purchase of a video...\n",
      "1          Aight, I'll hit you up when I get some cash\n",
      "2                           Don no da:)whats you plan?\n",
      "3                        Going to take your babe out ?\n",
      "4    No need lar. Jus testing e phone card. Dunno n...\n",
      "dtype: object\n",
      "\n",
      "After removing Stop Words\n",
      "0    LookAtMe ! : Thanks purchase video clip LookAt...\n",
      "1                         Aight , I 'll hit I get cash\n",
      "2                              Don da : ) whats plan ?\n",
      "3                                    Going take babe ?\n",
      "4    No need lar . Jus testing e phone card . Dunno...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dfXDemo = X_train.copy()\n",
    "print(\"Original\")\n",
    "print(X_train.head())\n",
    "dfXDemo = dfXDemo.apply(removeStopWords)\n",
    "print(\"\\nAfter removing Stop Words\")\n",
    "print(dfXDemo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0ca86-9c26-447f-a630-04283f51778d",
   "metadata": {},
   "source": [
    "The **apply()** function passes one row at a time from the dataset to the function (in this case the function is removeStopWords()) and sends the output of the function to the destination variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da82b8b4-814d-4f10-804e-f74e64b032ac",
   "metadata": {},
   "source": [
    "#### Function to remove Special Characters\n",
    "\n",
    "Next, we remove all the special characters from the text. Now, this is a debatable case as spam emails might contain some sequences of special characters. So, ideally we should have been classifying them as well. However, for the sake of simplicity, we will remove the special characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c42c83b2-fc28-4d6a-99f8-25ce23d971fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeSpecialCharacters(text):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    return re.sub(pattern, '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc275f4-7b3c-4f78-ba51-03a0e8432746",
   "metadata": {},
   "source": [
    "This function replaces any character in the input which is not an alphabet or a digit or a space character with an empty string. So, in the process, any character other than alphabets, digits and space characters gets eliminated from the input.\n",
    "\n",
    "Let us test this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59a29274-4586-4e3e-a69e-bdbb7d2859c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test tring sent to someone'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeSpecialCharacters(\"'This'; is a #test $tring, sent: to @someone.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1665e84c-687b-44f0-ad16-31160920b328",
   "metadata": {},
   "source": [
    "#### Function to remove Numbers\n",
    "\n",
    "Numbers in the text will definitely not help us identify spam mails. So, we remove all the numbers present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b353e3f9-70d4-4522-ae78-0cd9e5a25c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeNumbers(text):\n",
    "    return re.sub('([0-9]+)', '', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd47fbc4-fd0b-48d4-8ba8-49254cc9977e",
   "metadata": {},
   "source": [
    "Let us test our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eff09a35-2354-424e-9b78-cbc9695dd330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This text contains  numbers and  characters.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeNumbers(\"This text contains 66 numbers and 1654 characters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22abed0-c479-4c20-bceb-aff07e415300",
   "metadata": {},
   "source": [
    "#### Function to remove extra spaces\n",
    "\n",
    "Extra Spaces contribute nothing to building the model. Extra Spaces may be present in the raw data and/or could have been introduced due to the operations we performed earlier. So, we need to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86d2929e-63fd-4b70-b121-6b50f8f3dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeExtraWhiteSpaces(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec677fe0-80be-40a6-acb4-5f7e9390bdd6",
   "metadata": {},
   "source": [
    "Let us test our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8350136f-b496-47e8-bdb2-b5faeafb9403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test of removing extra white spaces'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeExtraWhiteSpaces(\"This   is a    test of removing     extra white    spaces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867281c1-e008-4119-8f92-cc606f169f76",
   "metadata": {},
   "source": [
    "### Putting together the functions to create a single function to clean the data\n",
    "\n",
    "We now put together all the individual functions we have written so far so that we have a single function that can clean the input data. We will run this function on the Training dataset first and get to the next step in formulating the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af3b2077-9c11-4551-a490-124b6f0d30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(text):\n",
    "    text = removeSpecialCharacters(text)\n",
    "    text = removeStopWords(text)\n",
    "    text = removeNumbers(text)\n",
    "    text = removeExtraWhiteSpaces(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c8e99-913d-4c64-b346-f9b5092379d7",
   "metadata": {},
   "source": [
    "Now that our function is ready, we will apply this function on our input data. We will treat only the text in the X_train dataset for the moment as this is what we will use for training our model.\n",
    "\n",
    "Before applying the function, we convert all the data to lowercase. This is so that all the similar words appear the same. For example, the word \"Same\" may be used in the text as \"Same\", \"SAME\", \"same\" or in any other way. If we do not convert all the text to either lower case or upper case, all the different representations of the same word will appear as distinct entities. Having the same word as different entities does not add any value to the Spam Detector. Suppose, we consider that the word \"free\" is used in Spam. So, we need to find out how frequently the word \"free\" is used in the text of an Email. Here, if we give a different treatment to the different representations of the word \"free\", then our model will become weak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed257ae4-67fa-415a-87fb-2b930274ec20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    lookatme thanks purchase video clip lookatme y...\n",
       "1                               aight ill hit get cash\n",
       "2                                         dawhats plan\n",
       "3                                      going take babe\n",
       "4    need lar jus testing e phone card dunno networ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.str.lower()\n",
    "X_train = X_train.apply(cleanData)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb57e2c-b5e7-40d1-a5c5-a1d0550d8ee5",
   "metadata": {},
   "source": [
    "### Convert our text matter to numbers\n",
    "\n",
    "Now that we have a clean set of data, we need to convert this text data to numbers so that the computer can use it to model the data. There are number of ways to convert text data to numbers. We will see 2 such methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b65efe-3853-4395-b607-8a5b06bac3e3",
   "metadata": {},
   "source": [
    "#### Convert using TF-IDF Vectoriser\n",
    "\n",
    "We will now create the **TF-IDF Vectors**. \n",
    "\n",
    "To create the TF-IDF Vectors, we will use the **TfidfVectorizer** from the SciKit-Learn library as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4170abb-97f6-4ec7-988d-43904d1e3004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original Training Data: (5014,)\n",
      "Shape of transformed Training Data: (5014, 87653)\n"
     ]
    }
   ],
   "source": [
    "from   sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df = 0, use_idf = True, ngram_range = (1, 4))\n",
    "tfidfText = tfidf.fit_transform(X_train)\n",
    "print('Shape of original Training Data:', X_train.shape)\n",
    "print('Shape of transformed Training Data:', tfidfText.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8d31e-a223-4d8f-8feb-17409a32bd8e",
   "metadata": {},
   "source": [
    "So, we see that we originally had one column containing all the text. After transforming using TfidfVectorizer, we now have 87653 columns.\n",
    "\n",
    "Let us see what this transformed data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c081b9cc-bdef-40e3-a2f3-b1be27afa0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfText.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e4804-aa5e-4b9d-9374-b81b90a47ad6",
   "metadata": {},
   "source": [
    "We convert the TF-IDF vectors to a dataframe as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ecc1ee1-6a88-4f94-a600-7039cfcb3d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>____</th>\n",
       "      <th>____ joys</th>\n",
       "      <th>____ joys father</th>\n",
       "      <th>____ joys father ans</th>\n",
       "      <th>_ll</th>\n",
       "      <th>_ll finish</th>\n",
       "      <th>_ll finish buying</th>\n",
       "      <th>_ll submitting</th>\n",
       "      <th>_ll submitting da</th>\n",
       "      <th>_ll submitting da project</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom cine</th>\n",
       "      <th>zoom cine actually</th>\n",
       "      <th>zoom cine actually tonight</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zouk nichols</th>\n",
       "      <th>zouk nichols parisfree</th>\n",
       "      <th>zouk nichols parisfree roses</th>\n",
       "      <th>zs</th>\n",
       "      <th>zs subscription</th>\n",
       "      <th>zs subscription pw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5014 rows × 87653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ____  ____ joys  ____ joys father  ____ joys father ans  _ll  \\\n",
       "0      0.0        0.0               0.0                   0.0  0.0   \n",
       "1      0.0        0.0               0.0                   0.0  0.0   \n",
       "2      0.0        0.0               0.0                   0.0  0.0   \n",
       "3      0.0        0.0               0.0                   0.0  0.0   \n",
       "4      0.0        0.0               0.0                   0.0  0.0   \n",
       "...    ...        ...               ...                   ...  ...   \n",
       "5009   0.0        0.0               0.0                   0.0  0.0   \n",
       "5010   0.0        0.0               0.0                   0.0  0.0   \n",
       "5011   0.0        0.0               0.0                   0.0  0.0   \n",
       "5012   0.0        0.0               0.0                   0.0  0.0   \n",
       "5013   0.0        0.0               0.0                   0.0  0.0   \n",
       "\n",
       "      _ll finish  _ll finish buying  _ll submitting  _ll submitting da  \\\n",
       "0            0.0                0.0             0.0                0.0   \n",
       "1            0.0                0.0             0.0                0.0   \n",
       "2            0.0                0.0             0.0                0.0   \n",
       "3            0.0                0.0             0.0                0.0   \n",
       "4            0.0                0.0             0.0                0.0   \n",
       "...          ...                ...             ...                ...   \n",
       "5009         0.0                0.0             0.0                0.0   \n",
       "5010         0.0                0.0             0.0                0.0   \n",
       "5011         0.0                0.0             0.0                0.0   \n",
       "5012         0.0                0.0             0.0                0.0   \n",
       "5013         0.0                0.0             0.0                0.0   \n",
       "\n",
       "      _ll submitting da project  ...  zoom cine  zoom cine actually  \\\n",
       "0                           0.0  ...        0.0                 0.0   \n",
       "1                           0.0  ...        0.0                 0.0   \n",
       "2                           0.0  ...        0.0                 0.0   \n",
       "3                           0.0  ...        0.0                 0.0   \n",
       "4                           0.0  ...        0.0                 0.0   \n",
       "...                         ...  ...        ...                 ...   \n",
       "5009                        0.0  ...        0.0                 0.0   \n",
       "5010                        0.0  ...        0.0                 0.0   \n",
       "5011                        0.0  ...        0.0                 0.0   \n",
       "5012                        0.0  ...        0.0                 0.0   \n",
       "5013                        0.0  ...        0.0                 0.0   \n",
       "\n",
       "      zoom cine actually tonight  zouk  zouk nichols  zouk nichols parisfree  \\\n",
       "0                            0.0   0.0           0.0                     0.0   \n",
       "1                            0.0   0.0           0.0                     0.0   \n",
       "2                            0.0   0.0           0.0                     0.0   \n",
       "3                            0.0   0.0           0.0                     0.0   \n",
       "4                            0.0   0.0           0.0                     0.0   \n",
       "...                          ...   ...           ...                     ...   \n",
       "5009                         0.0   0.0           0.0                     0.0   \n",
       "5010                         0.0   0.0           0.0                     0.0   \n",
       "5011                         0.0   0.0           0.0                     0.0   \n",
       "5012                         0.0   0.0           0.0                     0.0   \n",
       "5013                         0.0   0.0           0.0                     0.0   \n",
       "\n",
       "      zouk nichols parisfree roses   zs  zs subscription  zs subscription pw  \n",
       "0                              0.0  0.0              0.0                 0.0  \n",
       "1                              0.0  0.0              0.0                 0.0  \n",
       "2                              0.0  0.0              0.0                 0.0  \n",
       "3                              0.0  0.0              0.0                 0.0  \n",
       "4                              0.0  0.0              0.0                 0.0  \n",
       "...                            ...  ...              ...                 ...  \n",
       "5009                           0.0  0.0              0.0                 0.0  \n",
       "5010                           0.0  0.0              0.0                 0.0  \n",
       "5011                           0.0  0.0              0.0                 0.0  \n",
       "5012                           0.0  0.0              0.0                 0.0  \n",
       "5013                           0.0  0.0              0.0                 0.0  \n",
       "\n",
       "[5014 rows x 87653 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain = pd.DataFrame(tfidfText.todense(), columns=tfidf.get_feature_names())\n",
    "dfTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119f8de-80bd-4457-9c2d-7e9c0bd89de7",
   "metadata": {},
   "source": [
    "To the above dataframe, we will add the series URLPresent which indicates whether the text contained a URL or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8462d70-e529-4250-b1a5-8693ddf315df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>____</th>\n",
       "      <th>____ joys</th>\n",
       "      <th>____ joys father</th>\n",
       "      <th>____ joys father ans</th>\n",
       "      <th>_ll</th>\n",
       "      <th>_ll finish</th>\n",
       "      <th>_ll finish buying</th>\n",
       "      <th>_ll submitting</th>\n",
       "      <th>_ll submitting da</th>\n",
       "      <th>_ll submitting da project</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom cine actually</th>\n",
       "      <th>zoom cine actually tonight</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zouk nichols</th>\n",
       "      <th>zouk nichols parisfree</th>\n",
       "      <th>zouk nichols parisfree roses</th>\n",
       "      <th>zs</th>\n",
       "      <th>zs subscription</th>\n",
       "      <th>zs subscription pw</th>\n",
       "      <th>URLPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87654 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ____  ____ joys  ____ joys father  ____ joys father ans  _ll  _ll finish  \\\n",
       "0   0.0        0.0               0.0                   0.0  0.0         0.0   \n",
       "1   0.0        0.0               0.0                   0.0  0.0         0.0   \n",
       "2   0.0        0.0               0.0                   0.0  0.0         0.0   \n",
       "3   0.0        0.0               0.0                   0.0  0.0         0.0   \n",
       "4   0.0        0.0               0.0                   0.0  0.0         0.0   \n",
       "\n",
       "   _ll finish buying  _ll submitting  _ll submitting da  \\\n",
       "0                0.0             0.0                0.0   \n",
       "1                0.0             0.0                0.0   \n",
       "2                0.0             0.0                0.0   \n",
       "3                0.0             0.0                0.0   \n",
       "4                0.0             0.0                0.0   \n",
       "\n",
       "   _ll submitting da project  ...  zoom cine actually  \\\n",
       "0                        0.0  ...                 0.0   \n",
       "1                        0.0  ...                 0.0   \n",
       "2                        0.0  ...                 0.0   \n",
       "3                        0.0  ...                 0.0   \n",
       "4                        0.0  ...                 0.0   \n",
       "\n",
       "   zoom cine actually tonight  zouk  zouk nichols  zouk nichols parisfree  \\\n",
       "0                         0.0   0.0           0.0                     0.0   \n",
       "1                         0.0   0.0           0.0                     0.0   \n",
       "2                         0.0   0.0           0.0                     0.0   \n",
       "3                         0.0   0.0           0.0                     0.0   \n",
       "4                         0.0   0.0           0.0                     0.0   \n",
       "\n",
       "   zouk nichols parisfree roses   zs  zs subscription  zs subscription pw  \\\n",
       "0                           0.0  0.0              0.0                 0.0   \n",
       "1                           0.0  0.0              0.0                 0.0   \n",
       "2                           0.0  0.0              0.0                 0.0   \n",
       "3                           0.0  0.0              0.0                 0.0   \n",
       "4                           0.0  0.0              0.0                 0.0   \n",
       "\n",
       "   URLPresent  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 87654 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain['URLPresent'] = URLPresent\n",
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ad985-fc36-444c-8dde-2d3d6ca3de44",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes algorithm for Spam Detection using Scikit-Learn\n",
    "\n",
    "Now let us use the library provided in Scikit-Learn to implement the Naive Bayes algorithm for Spam Detection.\n",
    "\n",
    "There are many variations of Naive Bayes implementation provided in Scikit-Learn. We will discuss **Multinomial Naive Bayes** as this variation has been written specifically for implementing the Naive Bayes algorithm on TF-IDF Vectors.\n",
    "\n",
    "### Building the Multinomial Naive Bayes model\n",
    "\n",
    "For building the model, we need the training data and the associated labels. We built the TF-IDF vectors for the training data set and stored it in dfTrain. We have the corresponding labels in y_train. Using this, we can build our model as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73d86b77-c097-4873-b223-d31422be6af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(dfTrain.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba428c-8781-42d5-b6d9-c620517de679",
   "metadata": {},
   "source": [
    "Now our model has been prepared. Let us test how the model is working on the training set.\n",
    "\n",
    "To test the model, we need to make predictions from the model. As we are testing the training set first, we make predictions on the training dataset, i.e. dfTrain and compare the predictions with y_train. The below code demonstrates making a prediction on the training dataset using our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bf303f9-c508-4e22-a10e-77b42d7d2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrainPred = model.predict(dfTrain.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95ab0e-1eee-4308-8d51-a8217c614c6e",
   "metadata": {},
   "source": [
    "To compare the predictions made by the model with the actual data, we can use the **Confusion Matrix** as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d368238-e240-4a2e-b61f-81980bca86ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from   sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "confusionMatrix = metrics.confusion_matrix(y_train, yTrainPred)\n",
    "cmDisplay = metrics.ConfusionMatrixDisplay(confusion_matrix = confusionMatrix, display_labels = [False, True])\n",
    "cmDisplay.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1036db12-0ec7-46a6-87f1-ca7c2fa442be",
   "metadata": {},
   "source": [
    "From the above confusion matrix, we see that 4334 good SMS were truly classified by the model as good SMS and 556 spam SMS were classified by the model as spam. The model classified 0 good SMS as spam and 124 spam emails as good SMS.\n",
    "\n",
    "So, the accuracy of the model is (4334 + 556) / (4334 + 556 + 0 + 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3e22c10-e25b-4bd7-8c0a-b99d32898445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.97527\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy = %5.5f\" % ((4334 + 556) / (4334 + 556 + 0 + 124)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c07c3-050b-458f-a5c1-cd8a07af3009",
   "metadata": {},
   "source": [
    "We can also calculate the accuracy using functions available in Scikit-Learn as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15b7bd22-6b07-449f-bd29-b05561cf12e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.97527\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Accuracy = %5.5f\" % (metrics.accuracy_score(y_train, yTrainPred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f7f8a6-3358-466e-af14-d1e2e17f600f",
   "metadata": {},
   "source": [
    "### Validating the model on the test dataset\n",
    "\n",
    "We have seen the accuracy of the model on the training data. However, the training dataset was the dataset on which the model was built. We will now feed the test dataset (which the model has not yet seen) and check the accuracy of the model.\n",
    "\n",
    "We have kept the text dataset in the variable X_test and the corresponding labels in y_test. Before we can apply the model on the test dataset, we must transform the test dataset just like we transformed the training dataset. The below steps transform the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56b8dc09-0de0-4485-a11c-ee2e10f3cb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    funny fact nobody teaches volcanoes erupt tsun...\n",
       "1    sent scores sophas secondary application schoo...\n",
       "2     know someone know fancies call find pobox lshb p\n",
       "3    promise getting soon youll text morning let kn...\n",
       "4    congratulations ur awarded either cd gift vouc...\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLPresentTest = pd.Series([identifyAndRemoveURLs(text)[1] for text in X_test])\n",
    "X_test = pd.Series([identifyAndRemoveURLs(text)[0] for text in X_test])\n",
    "X_test = X_test.str.lower()\n",
    "X_test = X_test.apply(cleanData)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9e92325-e033-48ca-97f4-774e6157b91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original Test Data: (558,)\n",
      "Shape of transformed Test Data: (558, 87654)\n"
     ]
    }
   ],
   "source": [
    "tfidfTestText = tfidf.transform(X_test)\n",
    "dfTest = pd.DataFrame(tfidfTestText.todense(), columns=tfidf.get_feature_names())\n",
    "dfTest['URLPresent'] = URLPresentTest\n",
    "print('Shape of original Test Data:', X_test.shape)\n",
    "print('Shape of transformed Test Data:', dfTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb22700-6e9e-46d5-8629-aee33c6ed6c5",
   "metadata": {},
   "source": [
    "The important aspect to notice is that we applied the same instance of TF-IDF Vectorizer that we used for the training dataset. This is because we fit the TF-IDF Vectorizer on the training dataset and we **only transformed the test data using the fit we generated from the training dataset**.\n",
    "\n",
    "Now that we have transformed the test dataset, we can use to make predictions using the model we developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9147960c-10e8-4f63-85f6-f2d231101cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTestPred = model.predict(dfTest.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c4d6c8-eb90-403a-82f8-8f88d57fd09d",
   "metadata": {},
   "source": [
    "Let us generate the Confusion Matrix for the predictions made on the test dataset and check the goodness of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e35e45c0-e8d7-431b-b175-de2ebeec4d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix = metrics.confusion_matrix(y_test, yTestPred)\n",
    "cmDisplay = metrics.ConfusionMatrixDisplay(confusion_matrix = confusionMatrix, display_labels = [False, True])\n",
    "cmDisplay.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0155265-5b83-432c-ba56-ea3e584c34c5",
   "metadata": {},
   "source": [
    "Let us check the test accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4543cb5e-b25d-44cf-91b7-af7436dc3d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.97491\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy = %5.5f\" % (metrics.accuracy_score(y_test, yTestPred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8d0c6-06e5-4705-8d66-deddf6b69398",
   "metadata": {},
   "source": [
    "### Making predictions using our model\n",
    "\n",
    "We can feed new SMS into our model and get the predictions from the model. As I do not have a SMS, I will use a simple sentence in the English language as shown below. Here, I am explaining the mechanics and the same mechanics can be used by applying them on real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8668e513-83f1-477c-874a-005643853a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test sms checked spam'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSMS = \"This is a test SMS to be checked for spam\"\n",
    "URLPresentInSMS = identifyAndRemoveURLs(testSMS)[1]\n",
    "testSMS = identifyAndRemoveURLs(testSMS)[0]\n",
    "testSMS = testSMS.lower()\n",
    "testSMS = cleanData(testSMS)\n",
    "testSMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69500794-d3f0-4b3e-b2d0-cf6197f98367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 87654)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tfidfTestSMS = tfidf.transform([testSMS])\n",
    "arrTestSMS = tfidfTestSMS.toarray()\n",
    "arrTestSMS = np.append(arrTestSMS, URLPresentInSMS).reshape(1, -1)\n",
    "arrTestSMS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c21ad4db-44d7-4859-9ebd-5fb197412f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(arrTestSMS)\n",
    "le.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8ad08-b48c-4e55-bde3-b02e9a9f600d",
   "metadata": {},
   "source": [
    "So, our model predicts that if the text is as we have given, then the SMS could be good.\n",
    "\n",
    "Let us try one more example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efe5defd-5f2a-417a-9b92-d93a300cf383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSMS = \"You won the lottery. Click this link http://fake.com as soon as possible\"\n",
    "URLPresentInSMS = identifyAndRemoveURLs(testSMS)[1]\n",
    "testSMS = identifyAndRemoveURLs(testSMS)[0]\n",
    "testSMS = testSMS.lower()\n",
    "testSMS = cleanData(testSMS)\n",
    "tfidfTestSMS = tfidf.transform([testSMS])\n",
    "arrTestSMS = tfidfTestSMS.toarray()\n",
    "arrTestSMS = np.append(arrTestSMS, URLPresentInSMS).reshape(1, -1)\n",
    "\n",
    "prediction = model.predict(arrTestSMS)\n",
    "le.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b41e0d-804b-4138-b05f-2e980975dcb9",
   "metadata": {},
   "source": [
    "Our model predicted that this SMS could be spam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
